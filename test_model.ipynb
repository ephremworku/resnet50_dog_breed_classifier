{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "model = torch.load('resnet50_dog_breed.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the same transformations as during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming 'model' is already defined and fine-tuned as per your script\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'valid/Shar_Pei/01.jpg'  # Replace with the actual path to your image\n",
    "image = Image.open(image_path)\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Move the image to the device\n",
    "image = image.to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# # Convert the predicted index to the corresponding class label\n",
    "# predicted_class = train_data.classes[predicted.item()]\n",
    "# print(f'Predicted class: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghan', 'African Wild Dog', 'Airedale', 'American Hairless', 'American Spaniel', 'Basenji', 'Basset', 'Beagle', 'Bearded Collie', 'Bermaise', 'Bichon Frise', 'Blenheim', 'Bloodhound', 'Bluetick', 'Border Collie', 'Borzoi', 'Boston Terrier', 'Boxer', 'Bull Mastiff', 'Bull Terrier', 'Bulldog', 'Cairn', 'Chihuahua', 'Chinese Crested', 'Chow', 'Clumber', 'Cockapoo', 'Cocker', 'Collie', 'Corgi', 'Coyote', 'Dalmation', 'Dhole', 'Dingo', 'Doberman', 'Elk Hound', 'French Bulldog', 'German Sheperd', 'Golden Retriever', 'Great Dane', 'Great Perenees', 'Greyhound', 'Groenendael', 'Irish Spaniel', 'Irish Wolfhound', 'Japanese Spaniel', 'Komondor', 'Labradoodle', 'Labrador', 'Lhasa', 'Malinois', 'Maltese', 'Mex Hairless', 'Newfoundland', 'Pekinese', 'Pit Bull', 'Pomeranian', 'Poodle', 'Pug', 'Rhodesian', 'Rottweiler', 'Saint Bernard', 'Schnauzer', 'Scotch Terrier', 'Shar_Pei', 'Shiba Inu', 'Shih-Tzu', 'Siberian Husky', 'Vizsla', 'Yorkie']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "classes = os.listdir('train')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image, model):\n",
    "    try:\n",
    "        # Ensure the same transformations as during training\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Device configuration\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Assuming 'model' is already defined and fine-tuned as per your script\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image_path = image  # Replace with the actual path to your image\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image)\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Move the image to the device\n",
    "        image = image.to(device)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # # Convert the predicted index to the corresponding class label\n",
    "        # predicted_class = train_data.classes[predicted.item()]\n",
    "        # print(f'Predicted class: {predicted_class}')\n",
    "        return predicted.item()\n",
    "    except Exception as e:\n",
    "        print(image)\n",
    "        return 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "json_to_return = {}\n",
    "data_tobe_returned = []\n",
    "\n",
    "names = os.listdir('kennel-uk-breed-imgs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "62\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "35\n",
      "67\n",
      "67\n",
      "67\n",
      "48\n",
      "48\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "69\n",
      "69\n",
      "21\n",
      "63\n",
      "59\n",
      "41\n",
      "43\n",
      "47\n",
      "5\n",
      "5\n",
      "13\n",
      "13\n",
      "68\n",
      "4\n",
      "44\n",
      "25\n",
      "8\n",
      "62\n",
      "6\n",
      "6\n",
      "68\n",
      "59\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "60\n",
      "60\n",
      "57\n",
      "57\n",
      "42\n",
      "42\n",
      "50\n",
      "44\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "46\n",
      "46\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "13\n",
      "34\n",
      "12\n",
      "12\n",
      "10\n",
      "49\n",
      "14\n",
      "14\n",
      "21\n",
      "50\n",
      "15\n",
      "11\n",
      "16\n",
      "16\n",
      "62\n",
      "62\n",
      "17\n",
      "17\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "62\n",
      "62\n",
      "68\n",
      "11\n",
      "19\n",
      "19\n",
      "5\n",
      "19\n",
      "20\n",
      "7\n",
      "18\n",
      "18\n",
      "21\n",
      "63\n",
      "65\n",
      "33\n",
      "40\n",
      "35\n",
      "8\n",
      "8\n",
      "11\n",
      "27\n",
      "62\n",
      "62\n",
      "22\n",
      "56\n",
      "22\n",
      "20\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "68\n",
      "59\n",
      "28\n",
      "28\n",
      "28\n",
      "41\n",
      "49\n",
      "49\n",
      "38\n",
      "4\n",
      "0\n",
      "53\n",
      "59\n",
      "68\n",
      "62\n",
      "62\n",
      "34\n",
      "34\n",
      "44\n",
      "62\n",
      "31\n",
      "31\n",
      "51\n",
      "62\n",
      "44\n",
      "44\n",
      "34\n",
      "34\n",
      "59\n",
      "59\n",
      "27\n",
      "25\n",
      "34\n",
      "34\n",
      "9\n",
      "9\n",
      "53\n",
      "50\n",
      "24\n",
      "24\n",
      "67\n",
      "67\n",
      "65\n",
      "65\n",
      "59\n",
      "13\n",
      "41\n",
      "41\n",
      "63\n",
      "19\n",
      "36\n",
      "36\n",
      "4\n",
      "4\n",
      "59\n",
      "59\n",
      "50\n",
      "37\n",
      "68\n",
      "48\n",
      "56\n",
      "24\n",
      "56\n",
      "42\n",
      "13\n",
      "62\n",
      "62\n",
      "62\n",
      "21\n",
      "21\n",
      "27\n",
      "27\n",
      "13\n",
      "13\n",
      "39\n",
      "9\n",
      "9\n",
      "67\n",
      "65\n",
      "41\n",
      "17\n",
      "66\n",
      "66\n",
      "47\n",
      "47\n",
      "6\n",
      "6\n",
      "49\n",
      "8\n",
      "60\n",
      "9\n",
      "40\n",
      "40\n",
      "46\n",
      "46\n",
      "47\n",
      "62\n",
      "68\n",
      "59\n",
      "68\n",
      "59\n",
      "19\n",
      "5\n",
      "11\n",
      "25\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "44\n",
      "44\n",
      "41\n",
      "41\n",
      "8\n",
      "27\n",
      "21\n",
      "7\n",
      "65\n",
      "65\n",
      "45\n",
      "45\n",
      "65\n",
      "65\n",
      "56\n",
      "56\n",
      "42\n",
      "42\n",
      "13\n",
      "62\n",
      "45\n",
      "45\n",
      "46\n",
      "46\n",
      "14\n",
      "11\n",
      "33\n",
      "33\n",
      "8\n",
      "44\n",
      "47\n",
      "43\n",
      "2\n",
      "2\n",
      "60\n",
      "60\n",
      "27\n",
      "27\n",
      "53\n",
      "53\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "51\n",
      "51\n",
      "34\n",
      "34\n",
      "40\n",
      "40\n",
      "18\n",
      "18\n",
      "34\n",
      "59\n",
      "62\n",
      "62\n",
      "18\n",
      "48\n",
      "53\n",
      "53\n",
      "21\n",
      "21\n",
      "35\n",
      "67\n",
      "35\n",
      "35\n",
      "21\n",
      "21\n",
      "49\n",
      "10\n",
      "44\n",
      "47\n",
      "14\n",
      "45\n",
      "33\n",
      "25\n",
      "54\n",
      "54\n",
      "41\n",
      "3\n",
      "21\n",
      "63\n",
      "55\n",
      "19\n",
      "60\n",
      "8\n",
      "8\n",
      "34\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=318x257 at 0x2189938CD10>\n",
      "2000\n",
      "56\n",
      "56\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "57\n",
      "21\n",
      "21\n",
      "68\n",
      "39\n",
      "47\n",
      "53\n",
      "58\n",
      "58\n",
      "61\n",
      "40\n",
      "40\n",
      "40\n",
      "21\n",
      "8\n",
      "38\n",
      "23\n",
      "48\n",
      "48\n",
      "4\n",
      "43\n",
      "48\n",
      "4\n",
      "38\n",
      "40\n",
      "48\n",
      "48\n",
      "68\n",
      "38\n",
      "59\n",
      "59\n",
      "60\n",
      "60\n",
      "62\n",
      "62\n",
      "22\n",
      "22\n",
      "0\n",
      "15\n",
      "56\n",
      "56\n",
      "42\n",
      "42\n",
      "62\n",
      "62\n",
      "63\n",
      "63\n",
      "62\n",
      "63\n",
      "64\n",
      "64\n",
      "28\n",
      "28\n",
      "49\n",
      "8\n",
      "67\n",
      "67\n",
      "8\n",
      "23\n",
      "59\n",
      "41\n",
      "44\n",
      "62\n",
      "4\n",
      "27\n",
      "47\n",
      "47\n",
      "27\n",
      "27\n",
      "4\n",
      "4\n",
      "25\n",
      "25\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "4\n",
      "4\n",
      "43\n",
      "43\n",
      "4\n",
      "4\n",
      "6\n",
      "11\n",
      "47\n",
      "57\n",
      "61\n",
      "61\n",
      "55\n",
      "55\n",
      "42\n",
      "42\n",
      "37\n",
      "35\n",
      "53\n",
      "14\n",
      "54\n",
      "54\n",
      "49\n",
      "8\n",
      "6\n",
      "7\n",
      "48\n",
      "48\n",
      "38\n",
      "39\n",
      "68\n",
      "0\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "2\n",
      "2\n",
      "10\n",
      "63\n",
      "41\n",
      "41\n",
      "42\n",
      "40\n",
      "52\n",
      "3\n",
      "69\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "for x in names:\n",
    "    predicted_value = prediction('kennel-uk-breed-imgs/'+x, model=model)\n",
    "    print(predicted_value)\n",
    "    if predicted_value != 2000:\n",
    "        class_predicted = classes[predicted_value]\n",
    "    else:\n",
    "        class_predicted = f'undifined image {x}'\n",
    "    passed_image = x\n",
    "    json_to_return['Predicted Class']= class_predicted\n",
    "    json_to_return['Passed image'] = passed_image\n",
    "    data_tobe_returned.append(json_to_return)\n",
    "    json_to_return = {}\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out_file = open(\"predition_output.json\", \"w\")\n",
    "\n",
    "json.dump(data_tobe_returned, out_file, indent = 6)\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tortilaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
